{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263470f4-5780-446f-942d-ef19896427c7",
   "metadata": {},
   "source": [
    "# **Bonus: seuillage et filtres**\n",
    "\n",
    "## Introduction à l'analyse des images - 32M7132\n",
    "\n",
    "*Adrien Jeanrenaud (adrien.jeanrenaud@unige.ch)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b5941c-3650-4d29-bb91-6a2475736606",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Bonus</b> : le seuillage permet de définir des conditions dans notre matrice alors que l'application d'un filtre sur une image vient simplement modifier la matrice. Tout d'abord, nous verrons qu'est-ce que le seuillage et à quoi cela sert-il? Dans un second temps, il s'agira de voir ce qu'est un filtre, comment le créer et l'appliquer. Finalement, il s'agira de voir quelques-uns des filtres les plus courants, leur intérêt et leur application:\n",
    "</div>\n",
    "\n",
    "## **Plan du cours**\n",
    "\n",
    "> **Qu'est-ce que le seuillage?**\n",
    "> * Comment définir un seuil\n",
    "> * Et le seuillage adaptatif ?\n",
    "\n",
    "> **Qu'est-ce qu'un filtre?**\n",
    "> * Construire un filtre\n",
    "> * Attention aux bords\n",
    "> * Du filtre à l'image\n",
    "\n",
    "> **Des filtres pour réduire le bruit**\n",
    "> * Filtre moyen\n",
    "> * Filtre médian\n",
    "> * Filtre Gaussien\n",
    "> * Quoi d'autre ?\n",
    "\n",
    "> **Des filtres pour détecter les contours**\n",
    "> * Filtre Prewitt\n",
    "> * Filtre Sobel\n",
    "> * Filtre Canny\n",
    "> * Quoi d'autre ?\n",
    "> * Détecter des lignes et des contours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944909a9-b56a-4e33-ba02-6b04a6c7c35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer les librairies nécessaires\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7caf239-9b2b-4898-ad0d-1cbc716b4057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer une image\n",
    "\n",
    "image = \" \"\n",
    "img = cv2.imread(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cac6d9-82b4-4de9-9b68-4df5b6e81d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser en couleurs\n",
    "\n",
    "color = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e268e-4ca3-461a-964d-b5d95a7d971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# et en valeurs de gris\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca33753-681b-42f6-8f2c-65be72f99a59",
   "metadata": {},
   "source": [
    "## **Qu'est-ce que le seuillage?**\n",
    "\n",
    "Le principe du seuillage (threshold) est de passser d'une image en valeurs de gris à une image binaire. Une image binaire signifie que chaque pixel n'a que deux choix pour valeur, le plus souvent noir ou blanc. \n",
    "\n",
    "Cependant, il existe des manières de faire un seuillage qui ne rendent pas une image binaire. \n",
    "\n",
    "Le seuillage sert à mettre à jour une partie de l'image, un objet en particulier ou des particularités de l'image. Pour pouvoir appliquer un seuillage à une image, il faut nécessairement choisir un seuil, voire deux, qui diviseront la répartition des pixels\n",
    "\n",
    "### Comment définir un seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a742ef-a36a-4005-b2e5-e40f5f79e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "?cv2.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d84a327-2ccb-4d5b-bf93-336eca1862de",
   "metadata": {},
   "source": [
    "**Il existe différentes manières de faire du seuillage**\n",
    "\n",
    "> * cv2.THRESH_BINARY\n",
    "> * cv2.THRESH_BINARY_INV\n",
    "> * cv2.THRESH_TRUNC\n",
    "> * cv2.THRESH_TOZERO\n",
    "> * cv2.THRESH_TOZERO_INV\n",
    "\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTAV-GFewemqDFWCNbWo02LwZ5-Z6aqSRFF8SpK1QKP1mPmnnhB\" title=\"threshold\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a605cc78-b81f-40de-b633-8a5e813a142b",
   "metadata": {},
   "source": [
    "#### cv2.THRESH_BINARY\n",
    "\n",
    "Cette binarisation est la plus simple. Un seuil détermine les valeurs qui seront mises à 0 ou à 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561941aa-83b2-421b-aa11-da19a09c6684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La fonction prend comme argument: une image, un seuil, une valeur maximale et un type de seuillage\n",
    "# La fonction retourne: le seuil et l'image binarisée\n",
    "\n",
    "_, gray_b = cv2.threshold(gray, 70, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3d9b1-6b47-4adb-b1a0-ebc96b9a8a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"seuil :\", _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1815b050-a780-4aac-ae8e-77264ed42261",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_b,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32c726-295c-42af-8a8d-326da8c5885c",
   "metadata": {},
   "source": [
    "#### cv2.THRESH_BINARY_INV\n",
    "\n",
    "Cette binarisation est l'inverse de la précédente. Si le pixel est supérieur au seuil, alors la valeur maximale lui sera assignée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6154a1db-50e8-46bb-a901-763e0ee06e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La fonction prend comme argument: une image, un seuil, une valeur maximale et un type de seuillage\n",
    "# La fonction retourne: le seuil et l'image binarisée\n",
    "\n",
    "_, gray_bi = cv2.threshold(gray, 70, 255, cv2.THRESH_BINARY_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155e4c6-b403-4bca-a7b3-141ad423c0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_bi,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04b4bd1-508d-45ff-b7ae-7558ff6a012a",
   "metadata": {},
   "source": [
    "#### cv2.THRESH_THRESH_TRUNC\n",
    "\n",
    "Ce seuillage permet, par le choix d'un seuil T, de transformer tous les pixels supérieurs à la valeur du seuil tandis que les pixels en dessous du seuil ne sont pas modifiés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa8c7f-62a4-4a7c-b4b3-4ece60265be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La fonction prend comme argument: une image, un seuil, une valeur maximale et un type de seuillage\n",
    "# La fonction retourne: le seuil et l'image binarisée\n",
    "\n",
    "_, gray_t = cv2.threshold(gray, 70, 255, cv2.THRESH_TRUNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4a31e0-f01a-4f2f-98a7-4c288afef4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_t,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da78a0f6-17c1-4044-a373-d1a44c6cce4d",
   "metadata": {},
   "source": [
    "#### cv2THRESH_TOZERO\n",
    "\n",
    "Ici il s'agit de définir un seuil dont les valeurs, si elles sont inférieures au seuil, sont mises à 0 tandis que les valeurs supérieures au seuil ne changent pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d89100f-5cdf-4862-b29f-5e66ce73c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La fonction prend comme argument: une image, un seuil, une valeur maximale et un type de binarisation\n",
    "# La fonction retourne: le seuil et l'image binarisée\n",
    "\n",
    "_, gray_z = cv2.threshold(gray, 70, 255, cv2.THRESH_TOZERO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38359e09-df1e-473e-86c6-86fdd7e98e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_z,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a4f1cf-54e8-4052-9c45-35f4cf1e86e0",
   "metadata": {},
   "source": [
    "#### cv2.THRESH_TOZERO_INV\n",
    "\n",
    "Cette méthode est similaire à la précédente, à la seule différence que les valeurs en dessus du seuil sont cette fois mises à 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc2624-f0f1-425d-9885-eeba69f74dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La fonction prend comme argument: une image, un seuil, une valeur maximale et un type de binarisation\n",
    "# La fonction retourne: le seuil et l'image binarisée\n",
    "\n",
    "_, gray_zi = cv2.threshold(gray, 70, 255, cv2.THRESH_TOZERO_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0f6ef2-b490-413f-bbd3-063babc39fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_zi,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cc5b9c-8043-4fc3-8cd1-c2671df37480",
   "metadata": {},
   "source": [
    "**Il est également possible de définir le seuillage par un nombre au lieu d'appeler une fonction OpenCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213f8f10-4601-467d-8a87-bcfc5912c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Thresholding\n",
    "# 0, binary\n",
    "# 1, binary inverted\n",
    "# 2, Truncated\n",
    "# 3, Threshold to Zero\n",
    "# 4, Threshold to Zero inverted\n",
    "\n",
    "_, gray0 = cv2.threshold(gray, 70, 255, 0)\n",
    "_, gray1 = cv2.threshold(gray, 70, 255, 1)\n",
    "_, gray2 = cv2.threshold(gray, 70, 255, 2)\n",
    "_, gray3 = cv2.threshold(gray, 70, 255, 3)\n",
    "_, gray4 = cv2.threshold(gray, 70, 255, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f5618-40b5-4536-9abb-5203a70e8817",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"original\", 'BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [gray, gray0, gray1, gray2, gray3, gray4,]\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(images[i],cmap=\"gray\")\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ce463-a428-42e4-9ce4-1ba78d22e331",
   "metadata": {},
   "source": [
    "### Et le seuillage adaptatif ?\n",
    "\n",
    "Le seuillage adaptatif s'adapte aux régions de l'image. Il permet de s'adapter, par exemple, aux différentes conditions lumineuses. De fait, le seuillage n'est pas uniforme sur toute l'image, et aucune adapatation manuelle n'est nécessaire. \n",
    "\n",
    "**Deux types de seuillage adaptatif principalement**\n",
    "\n",
    "> * cv2.ADAPTIVE_THRESH_MEAN_C : le seuillage adaptatif moyen\n",
    "> * cv2.ADAPTIVE_THRESH_GAUSSIAN_C : le seuillage adaptatif gaussien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41879e42-5f8b-4e61-b630-91b6b5a7e7f5",
   "metadata": {},
   "source": [
    "#### cv2.ADAPTIVE_THRESH_MEAN_C\n",
    "\n",
    "Seuillage adapatatif avec un calcul de moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c396d-9a86-492d-a9ce-70d2ea31e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seuillage adaptatif moyen\n",
    "# La fontion prend en entrée : une image, la valeur max, la méthode adaptative, \n",
    "                            # la méthode de binairsation, la taille du voisinage, la valeur à soustraire à la moyenne du voisinage pour affiner le seuillage\n",
    "\n",
    "graySM = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e827f47-43fa-42c0-a960-5b3dff98bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(graySM,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92738458-55ae-404d-a857-4fae1397eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray[:10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd422b7-ab30-4743-8c55-dad74541a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "graySM[:10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f9bff-fba3-45de-9eb0-fb3728df85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il est également possible de passer de cette image à l'image couleur\n",
    "\n",
    "graySG1MB = cv2.bitwise_and(color, color, mask=graySM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f51098-4698-4357-b6ac-b2e6cca8a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(color)\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(graySG1MB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8780c5dc-1b35-4e25-820d-df2713707756",
   "metadata": {},
   "source": [
    "#### cv2.ADAPTIVE_THRESH_MEAN_C\n",
    "\n",
    "Seuillage adapatatif avec une moyenne pondérée (gaussienne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fb78d2-b3e9-468e-b205-039d82a88bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seuillage adaptatif avec uen gaussienne\n",
    "# La fontion prend en entrée : une image, la nouvelle valeur, la méthode adaptative, \n",
    "                            # la méthode de binairsation, la taille du voisinage, la valeur à soustraire à la moyenne pour affiner le seuillage\n",
    "\n",
    "graySG = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 9, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c49d1-3d92-45ee-8ad3-1e376a8da81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(graySG,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9396782-e404-4101-9224-2ac175dcadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray[:10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cef3cf-f9bb-474e-8f25-83897622826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graySG[:10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8a17bf-3e08-4458-9935-ddf84abcbd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher\n",
    "\n",
    "graySG2MB = cv2.bitwise_and(color, color, mask=graySG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd6d375-afe6-42b5-bd59-2f41ec07c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(color)\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(graySG2MB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dfd018-a91e-4d80-abec-5f05a8516282",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercice</b>: à partir d'une de vos images dans laquelle vous voulez mettre quelque chose en relief: choisissez un seuillage normal ou adapatatif et, à l'aide du code ci-dessous, dessinez les contours. Vous fournirez votre image avec le code.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87bfa4-c690-4587-b809-b3545216338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour dessiner les contours\n",
    "\n",
    "countours,hierarchy=cv2.findContours(img_binaire,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(color,countours,-1,(0,255,0),3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def26eae-5f12-4566-b792-4448156265a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b959d6-d5e0-431e-a0e7-0b3fb0118fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28ccb48a-ef7d-4ad1-822e-1bb11389e8e1",
   "metadata": {},
   "source": [
    "## **Qu'est-ce qu'un filtre?**\n",
    "###  Créer un filtre\n",
    "\n",
    "Dans le traitement numérique des images, les filtres sont utilisés principalement pour flouter, améliorer la netteté ou détecter les contours d'une image. Le filtre permet de supprimer les impurtées, le plus souvent il prépare l'image en vue d'opérations plus poussées. \n",
    "\n",
    "Un filtre est une petite matrice de dimension impair (3x3, 9x9, etc.) qui s'applique par convolution à l'image. Une convolution est simplement un opération matriciel entre le filtre et l'image. Le filtre (une matrice de 3x3 par exemple), se déplace sur l'image et une nouvelle image est obtenue lorsque l'opération de convolution est effectuée sur chaque pixel.\n",
    "L'opération de convolution réduit la taille de l'image, à moins que des bords soient ajoutés. \n",
    "\n",
    "<img src=\"https://miro.medium.com/proxy/0*YfpMfPnz6n2g4vIz.jpg\" title=\"filtre\"/>\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/William-Overell/publication/315478232/figure/fig30/AS:671530967113758@1537116867792/Concept-of-convolution-Our-kernel-mask-is-shown-below-as-M-From.ppm\" title=\"filtre2\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfae608e-5438-4acc-becd-9a1cfea1feee",
   "metadata": {},
   "source": [
    "### Attention aux bords\n",
    "\n",
    "Le déplacement du filtre sur l'image pose la question du traitement des bords, car les pixels aux extrémités de l'image doivent avoir le même traitement que les autres ; c'est-à-dire qu'ils doivent passer par toutes les composantes du filtre. Dans ce cas, il y a plusieurs méthodes pour élargir les bords de l'image afin que tous les pixels de l'image de base soient traités correctement. Le processus de création de données en dehors de l'image s'appelle en anglais \"padding\".\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmiro.medium.com%2Fmax%2F3232%2F1*9reDuDh3nXs_kJ-M4eq0Ow.png&f=1&nofb=1&ipt=5e8431d61861a6afe5ece799945d9a7a3841a1e80ad8eb42c80e8c5b4f567755&ipo=images\" title=\"padding\"/>\n",
    "\n",
    "\n",
    "**Principalement, il y a**\n",
    "> * ajout de zéros\n",
    "> * constante arbitraire\n",
    "> * plus proche voisin\n",
    "> * en miroir \n",
    "> * reprend le bors opposé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad21540-4201-42d7-9644-b1ead0543618",
   "metadata": {},
   "source": [
    "### Du filtre à l'image\n",
    "\n",
    "Il existe plusieurs types de filtres dont le paramétrage et les effets sont bien connus. Avant de les aborder, regardons comment l'on peut simplement créer et appliquer un fitlre sur notre image.\n",
    "\n",
    "https://setosa.io/ev/image-kernels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6cd4d0-5f9d-45e4-9661-68965dc3193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La fonction convolve de la librairie Scipy nous permet d'opérer une convolution sur une image \n",
    "# Regardons ses paramètres\n",
    "\n",
    "import scipy.ndimage\n",
    "\n",
    "?scipy.ndimage.filters.convolve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b8e5a2-d595-4098-8ffa-6630e3c7d4bd",
   "metadata": {},
   "source": [
    "**Il nous faut principalement une image (input), un filtre (weights) et un choix de padding (mode)**\n",
    "**À vous de faire**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11be4cf-f613-4045-908b-6b55721d6217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un filtre, 3x3 par exemple\n",
    "\n",
    "filtre = np.array([[1,0,1],\n",
    "                  [0,1,0],\n",
    "                  [1,0,1]])\n",
    "print(filtre.shape, \"\\n\", filtre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97276ec7-a6bc-42ed-b629-4984eecb0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrer la convolution\n",
    "\n",
    "grayf = gray.copy()\n",
    "\n",
    "gray_filtre = scipy.ndimage.filters.convolve(grayf, filtre, mode=\"reflect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5b73de-3894-4d72-b46a-28a09fe1174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_filtre,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0eb1ba-5256-4f23-a5e4-8b9681b1bdda",
   "metadata": {},
   "source": [
    "#### Fréquence?\n",
    "\n",
    "Nous avons créé un filtre au hasard. Il existe des filtres bien connus. Et pour comprendre leur application il faut considérer les images de manière un peu différente. Pour cela il faut comprendre l'imgage par la notion de fréquence.\n",
    "\n",
    "La fréquence traite normalement de la temporalité: par exemple, une voiture avance de deux bandes blanches par seconde. Une image peut être caractérisée par la quantification, la fréquence d'apparition d'un phénomène. Si un détail se répète on dira que la fréquence est élevée, dans le cas contraire on dira que le fréquence est basse.\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse4.mm.bing.net%2Fth%3Fid%3DOIP.RSYHbyQ1fPUG98ifqy6sZgHaC6%26pid%3DApi&f=1&ipt=bc9c46024b65e151d8fc12778cd302860c018f9a08d32a336c8f03087fc345c2&ipo=images\" title=\"freq\"/>\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Olivia-Cheung-2/publication/235368613/figure/fig1/AS:272536512495617@1441989176053/An-image-filtered-to-include-A-both-low-and-high-spatial-frequency-information-B.png\" title=\"freq1\"/>\n",
    "\n",
    "Je vous rassure tout de suite, nous continuons à travailler sur une image en pixels, comme nous l'avons fait jusqu'ici. Il s'agit simplement de comprendre la logique dérrière les hautes et les basses fréquences de l'image. Les filtres agissent sur ces fréquences en amplifiant ou réduisant leur spécificité.\n",
    "L'image ci-dessus, montre les deux principaux usages des filtres dans le traitement numérique des images : le flou (la réduction du bruit) et les bords (la détection des contours)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddca651-3a2e-431a-bfbd-819375075c19",
   "metadata": {},
   "source": [
    "## **Des filtres pour réduire le bruit**\n",
    "\n",
    "### Filtre moyen\n",
    "Le filtre moyen réduit le bruit tout en ne perdant pas la qualité de l'image.\n",
    "Il faut une matrice impaire remplie de 1, dont chaque valeur est divisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c325851-2f1e-417c-94b0-134a1cfd4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du filtre moyen\n",
    "# Une matrice de 5 par 5 \n",
    "# Chaque valeur (1) est divisée, faites des essais avec la division\n",
    "\n",
    "moyen = np.ones((5,5))/25\n",
    "\n",
    "print(\"Matrice :\\n\", moyen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48187266-1790-4ca9-bdeb-34997df88bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer le filtre par convolution\n",
    "\n",
    "graym = gray.copy()\n",
    "\n",
    "gray_moyen = scipy.ndimage.filters.convolve(graym, moyen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04db857-d9af-4da0-a16c-ccb1596a62c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_moyen,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efcf9d2-f347-4148-8c66-3f27823f9313",
   "metadata": {},
   "source": [
    "### Filtre médian\n",
    "\n",
    "Le filtre médian permet de réduire le bruit tout en conservant les contours, il est souvent utilisé pour supprimer le bruit sel et poivre (incursion de pixels noirs et blancs dans l'image) ; chaque pixel est remplacé par la médiane de son voisinage et cela permet de supprimer les valeurs abberantes. Le filtre médian garde le contraste, la luminosité et les contours\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse1.mm.bing.net%2Fth%3Fid%3DOIP.G_LpPCwe070BfCCditu_DgAAAA%26pid%3DApi&f=1&ipt=20c01b5071d474c71f35e8f93b75f34a9d315125d459abe62c841871db9b9e13&ipo=images\" title=\"mediane\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633e4441-092e-4fcd-ab7b-ed9726972d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "?scipy.ndimage.filters.median_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e546aa-33b0-4487-9811-b4dc0de0b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "# La fonction prend principalement en paramètres une image (input), la taille du filtre (size) et le type de padding (mode)\n",
    "\n",
    "gray_mm = gray.copy()\n",
    "\n",
    "gray_median = scipy.ndimage.filters.median_filter(gray_mm, size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394cfff-26a9-4500-92ad-284632a15d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_median,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590fdae2-69d3-4ee7-8fa7-e457dda2c2fe",
   "metadata": {},
   "source": [
    "### Filtre Gaussien\n",
    "\n",
    "Le filtre gaussien, comme son nom l'indique suit une distribution gaussienne, c'est-à-dire une loi normale centrée et réduite. Le sigma définit la forme de la cloche, et dans le traitement de l'image cela signifie que le bruit peut être réduit (sigma < 1) ou que le flou peut être accentué (sigma > 1).\n",
    "\n",
    "Le filtre gaussien vient lisser les imperfection de l'image, les détails et les contours sont atténués\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Generalized_normal_densities.svg/langfr-560px-Generalized_normal_densities.svg.png\" title=\"gauss\"/>\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse1.mm.bing.net%2Fth%3Fid%3DOIP.JpX8ONYKxZmIBAHIi1KpjAHaIy%26pid%3DApi&f=1&ipt=f751c30b941d608cdf6715c0829c2abc7c2d6f08aa83e0155fe4bef8ebc48ea9&ipo=images\" title=\"gauss2\"/>\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fsupport.cognex.com%2Fdocs%2Fcvl_900%2Fweb%2FEN%2Fcvl_vision_tools%2FContent%2FImages%2F18_8.jpg&f=1&nofb=1&ipt=0ba811ae846f092e40b20e9c7f1d74fc7f1e0f88240a48ec1ce7483ca4f1017b&ipo=images\" title=\"gauss3\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f062fd-2651-42cd-b201-f2c74abb415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "?scipy.ndimage.filters.gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddbe8cb-0552-43f1-b1cf-9752a6a2c5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "# La fonction prend principalement une image (input) et un sigma\n",
    "\n",
    "gray_g = gray.copy()\n",
    "\n",
    "gray_gauss = scipy.ndimage.filters.gaussian_filter(gray_g, sigma=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f182f9-6a18-428a-a14e-f6913938b5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_gauss,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af01c411-1698-4c30-891c-dab9d21684ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il existe également une fonction similaire dans la librairie OpenCV\n",
    "\n",
    "?cv2.GaussianBlur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1cd7ab-5a99-402b-9d29-fd00d7fcde83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "# La fonction prend principalement une image, une taille de filtre (ksize) et un sigma\n",
    "\n",
    "gray_gcv = gray.copy()\n",
    "\n",
    "gray_gausscv = cv2.GaussianBlur(gray_gcv, (19,19), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14010efe-697a-4ef3-a3dd-89598c1ee83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_gausscv,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733a9795-47ca-44f0-81cb-9c3a2d41a1db",
   "metadata": {},
   "source": [
    "### Quoi d'autre ?\n",
    "#### Filtre bilatéral\n",
    "\n",
    "Le filtre bilatéral permet de floutter une image tout en gardant les angles intacts. La méthode remplace la valeur de chaque pixel par la moyenne de l'intensité de ses voisins. Plus le \"sigma de la couleur\" est grand, plus les couleurs vont se mélanger tadivement ; plus le \"sigma de l'espace\" est grand, plus le nombre de pixels va se mélanger.\n",
    "Le point faible de ce filtre est le temps de calcul, donc de traitement des images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7869fbbf-0b6f-40b3-b41b-1976f19fd601",
   "metadata": {},
   "outputs": [],
   "source": [
    "?cv2.bilateralFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ef766-bb46-44e8-9385-2abee618a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "# La fonction prend principalement une image, le diamètre du voisinage des pixels (d) un sigma pour la couleur et un pour l'espace\n",
    "\n",
    "gray_b = gray.copy()\n",
    "\n",
    "gray_bilateral = cv2.bilateralFilter(gray_b, d = 9, sigmaColor=100, sigmaSpace=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d4144-a7fb-4d6a-9e95-1d2b9c7d042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_bilateral,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b0070a-238e-4567-83bc-d2c0cdd8cfff",
   "metadata": {},
   "source": [
    "**Pour aller plus loin: https://setosa.io/ev/image-kernels/**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e97a80-5471-4536-97b0-4838c3db71a4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercice </b>: à partir de l'exercice du cours 5 sur la détection de visages: reprenez le code et lorsque vous détecter un visage, faites en une nouvelle image que vous flouterez et enregistrerez.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8b0c8b-a075-4e48-aad7-03a112d72d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17680fc-132f-4669-9be6-38d87c9facfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc83fd3-55a4-43d4-97b7-3fcf2126e8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2be717-0c13-4d3a-bf8f-543726a66c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "140eae48-630a-4ea6-a93e-0a29134a1d71",
   "metadata": {},
   "source": [
    "## **Des filtres pour détecter les contours**\n",
    "\n",
    "Dans une image, un contour se comprend comme la différence d'intensité entre deux pixels. Mathématiquement le calcul d'intensité se fait par l'utilisation de dérivées : en somme, l'application de une ou deux dérivées permet d'accentuer le contraste entre deux parties de l'image sensées décrire un contour. Ainsi, la détection de contours cherche le changement soudain entre deux valeurs de pixel. \n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fi2.wp.com%2Fwww.adeveloperdiary.com%2Fwp-content%2Fuploads%2F2019%2F05%2FHow-to-implement-Sobel-edge-detection-using-Python-from-scratch-adeveloperdiary.com-sobel.jpg%3Fresize%3D600%252C281&f=1&nofb=1&ipt=429d15d804fa52c46efde3a1ffa086240b1a58a4d32969c28559b32185b03d89&ipo=images\" title=\"edge\"/>\n",
    "\n",
    "Il existe plusieurs types de filtres bien connus pour la détection des contours, nous allons en voir certains:\n",
    "\n",
    "* Prewitt\n",
    "* Sobel\n",
    "* Canny\n",
    "* Laplacien\n",
    "* Laplacien Gaussien\n",
    "\n",
    "\n",
    "La détection de contours se divise principalement en deux méthodes. D'un côté une méthode basée sur le gradient via la première dérivée : le gradient est le taux de varaiation d'un point en fonction de ses voisins. D'un autre côté une méthode basée sur une gaussienne à l'aide d'une derivée de second ordre. \n",
    "\n",
    "### Filtre Prewitt\n",
    "\n",
    "Le filtre Prewitt calcule approximativement l'intensité du gradient de manière peu couteuse. Ce filtre est utile pour détecter les contours verticaux ou horizontaux. Voilà à quoi ressemble d'une manière générale les deux masques du filtres Prewitt, un pour la partie verticale et un pour la partie horizontale:\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fcdn.analyticsvidhya.com%2Fwp-content%2Fuploads%2F2019%2F08%2Farticle-image-132-300x159.png&f=1&nofb=1&ipt=449a1fae2ba00cdd2cbb395a628c2b755f92fb7beb9dd8a2413c5204ef5d35e9&ipo=images\" title=\"edge\"/>\n",
    "\n",
    "Les filtres de la librairie skimage sont légèrement différents mais le principe est le même.\n",
    "#### Prewitt vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db67e62-33b4-4147-811a-7d5defdb7477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "?filters.prewitt_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cedc5f2-f69e-42b4-bce2-05b865d36586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "\n",
    "gray_pv = gray.copy()\n",
    "\n",
    "prewitt_v = filters.prewitt_v(gray_pv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a145be-22a3-492f-b8ad-53c0a7c5c25b",
   "metadata": {},
   "source": [
    "#### Prewitt horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c70aadb-14ed-4f85-85ff-32e50232502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "?filters.prewitt_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ac269-5d30-4ea7-b6a1-a35a606a0903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "\n",
    "gray_ph = gray.copy()\n",
    "\n",
    "prewitt_h = filters.prewitt_h(gray_pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c39a77-c09c-49d4-8efa-4391566adec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les deux images \n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Prewitt vertical\")\n",
    "plt.imshow(prewitt_v, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Prewitt horizontal\")\n",
    "plt.imshow(prewitt_h, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cb3dc2-91b5-4cbe-b1e6-a9c2f4baad89",
   "metadata": {},
   "source": [
    "### Filtre Sobel\n",
    "\n",
    "Le filtre Sobel a un principe similaire au filtre Prewitt, il détecte les contours horizontaux et verticaux . Il est plus utile pour les contours \"doux\" que ceux qui sont \"durs\" et malgré un coup de calcul réduit, le filtre produit un bruit indésirable. \n",
    "Voilà à quoi ressemble le masque Sobel:\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.omicsonline.org%2Farticles-images%2Fadvances-robotics-automation-sobel-kernel-feature-s2-008-g002.png&f=1&nofb=1&ipt=18a9b420c4e1adcae7faceeedf8b202d38b4a1c4555b8cd3eae389e7197f692d&ipo=images\" title=\"sobel\"/>\n",
    "\n",
    "#### Sobel vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c96c5d-6f47-4a6b-9503-96a84a3d69b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "?filters.sobel_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1607382-6ace-4eb6-8a45-e6a8e4033884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "\n",
    "gray_sv = gray.copy()\n",
    "\n",
    "sobel_v = filters.sobel_v(gray_sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f08120a-75eb-4798-9827-12bb556753ca",
   "metadata": {},
   "source": [
    "#### Sobel horizontal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4121b6-e605-4210-957b-77c8f960a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "?filters.sobel_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef5629b-b9f2-4956-9534-c6ce82b67f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "\n",
    "gray_sh = gray.copy()\n",
    "\n",
    "sobel_h = filters.sobel_h(gray_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c469f7-a3f1-498d-914c-4baea9bb816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les deux images \n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Sobel vertical\")\n",
    "plt.imshow(sobel_v, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Sobel horizontal\")\n",
    "plt.imshow(sobel_h, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a24d58-f7e4-4662-addc-aa61c0484a32",
   "metadata": {},
   "source": [
    "### Filtre Canny\n",
    "\n",
    "Le filtre Canny permet de détecter les contours (sans division horizontale et verticale préalable, comme le Sobel et Prewitt). Il est performant dans la détection (contours faibles et forts) et dans la localisation des contours (faible erreur entre contours détectés et contours réels). Malgré sa performance, son coup d'utilisation est non néglibeable.\n",
    "\n",
    "En d'autres termes, voilà le processus simplifié du filtre Canny:\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fimage.slidesharecdn.com%2Fe2822eef-6993-4540-9321-65ca5f35eb39-161009120200%2F95%2Fexploring-methods-to-improve-edge-detection-with-canny-algorithm-13-638.jpg%3Fcb%3D1476014597&f=1&nofb=1&ipt=f300f199eaf34361e890d50c9054e9b38c9b25b29d6863942c7ec716bbdbc49b&ipo=images\" title=\"k-means2\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1986a4b2-c228-4158-97c3-3ceb89d78c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "?cv2.Canny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8518be04-bdb9-4649-836d-e34b421f2ce7",
   "metadata": {},
   "source": [
    "**La fonction prend principalement comme arguments: une image, un seuil bas et un seuil haut**\n",
    "\n",
    "> * En dessous du seuil bas, le pixel est rejeté\n",
    "> * En dessus du seuil haut, le pixel est considéré comme un contour\n",
    "> * Entre, si le pixel est connecté au seuil haut, il est accepté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b49111-e496-4ef9-9114-260360013e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "\n",
    "gray_c = gray.copy()\n",
    "\n",
    "gray_canny = cv2.Canny(gray_c, 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7c830f-cde7-41a6-8555-f1bac6bb4e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_canny,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e49c1db-d350-496c-88a8-adfb98b936a6",
   "metadata": {},
   "source": [
    "### Quoi d'autre ?\n",
    "\n",
    "#### Laplacien Gaussien\n",
    "\n",
    "Le filtre laplacien gaussien: la gaussienne est ajoutée au filtre laplacien afin de reduire le bruit dû à l'application du filtre par l'image. La méthode fonctionne particulièrement bien lorsque la transititon est abrupte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776512a-7715-499d-b37e-7ec0a688d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "?scipy.ndimage.filters.gaussian_laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35808133-1162-4c0c-afc2-eab5cc5e0c02",
   "metadata": {},
   "source": [
    "**La fonction prend principalement comme arguments: une image, un sigma et un padding**\n",
    "\n",
    "> * Le mode de padding, comme vu précédemment\n",
    "> * Le sigma fonctionne un peu comme un seuil, plus il est élevé plus on perd de points saillants\n",
    "\n",
    "\n",
    "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fimage3.slideserve.com%2F5732879%2Flaplacian-of-gaussian-log-l.jpg&f=1&nofb=1&ipt=7de63d7d515aa0b0f2deab78c16be380dedb1cc5b2b9077ca489ce5c8171cfc5&ipo=images\" title=\"lg\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e4ba8-cad3-4fd9-b5ec-0125039b8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "\n",
    "gray_lg = gray.copy()\n",
    "\n",
    "gray_laplace_gauss = scipy.ndimage.filters.gaussian_laplace(gray_lg, sigma=2, mode=\"reflect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d681f07c-18ec-4f73-8178-71dafa388672",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_laplace_gauss,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f126f-0147-43f9-b5f5-9766d1d7ac79",
   "metadata": {},
   "source": [
    "#### Filtre de Frangi\n",
    "\n",
    "Le filtre de Frangi permet également de détecter des contours, il est principalement utile pour détecter des navires et des cours d'eau (mais aussi des veines, des nerfs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee1d4ca-e1d2-4264-ac45-175c0327dc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "?filters.frangi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67ab8f-abc4-4c87-a1df-161dbff12c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "\n",
    "gray_f = gray.copy()\n",
    "\n",
    "gray_frangi = filters.frangi(gray_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660a649-211d-4457-a497-e0907b30f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_frangi,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f516ea-263a-425e-957c-c2f39a541700",
   "metadata": {},
   "source": [
    "### Détecter des lignes et des contours\n",
    "\n",
    "#### Transformée de Hough\n",
    "\n",
    "Ce type de filtre est utilisé pour détecter des relations structurelles entre les pixels, c'est-à-dire la reconnaissance de structures simples comme des lignes ou des cercles. Pour minimiser le coup de traitement l'image est binarisée, réduite au noir et au blanc.\n",
    "\n",
    "##### Détection des lignes\n",
    "\n",
    "https://docs.opencv.org/3.4/d6/d10/tutorial_py_houghlines.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60064be5-b632-4806-bcb1-a4d7e494bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "?cv2.HoughLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d9eaa0-5ffc-4b76-93a6-c200a1508dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "\n",
    "gray_hl = gray.copy()\n",
    "\n",
    "edges = cv2.Canny(gray_hl,100,150,apertureSize = 3)\n",
    "\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength=100,maxLineGap=10)\n",
    "\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2 = line[0]\n",
    "    cv2.line(gray_hl,(x1,y1),(x2,y2),(0,255,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb141bd-53cc-4fcd-8579-d268ea69cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_hl,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2647d353-8716-4df4-a51d-3a3f5b95f63a",
   "metadata": {},
   "source": [
    "##### Détection des cercles\n",
    "\n",
    "https://docs.opencv.org/3.4/da/d53/tutorial_py_houghcircles.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df8aae3-865c-46a5-ba26-3d98c7634877",
   "metadata": {},
   "outputs": [],
   "source": [
    "?cv2.HoughCircles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d04503d-a4d8-40c7-a218-5af22f848fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage de la fonction\n",
    "\n",
    "gray_hc = gray.copy()\n",
    "\n",
    "img_blur = cv2.medianBlur(gray_hc, 5)\n",
    "\n",
    "circles = cv2.HoughCircles(img_blur, cv2.HOUGH_GRADIENT, 1,60,\n",
    "                            param1=50,param2=30,minRadius=0,maxRadius=0)\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0, :]:\n",
    "        cv2.circle(gray_hc, (i[0], i[1]), i[2], (0, 255, 0), 2)\n",
    "        cv2.circle(gray_hc, (i[0], i[1]), 2, (0, 0, 255), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2f23cd-21d9-415d-9c9b-21924906d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (20,10))\n",
    "                                                 \n",
    "ax1.set_title ('Image en valeurs de gris')\n",
    "ax1.imshow(gray,cmap = \"gray\")\n",
    "\n",
    "ax2.set_title ('Image transformée')\n",
    "ax2.imshow(gray_hc,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672966a4-52ff-474e-98b4-e089d81dce11",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Exercice </b>: à partir d'une image appliquer un filtre afin de détecter les contours. Afin de voir quelle partie de l'image en contient le plus, diviser préalablement votre image en motivant ce choix et expliquer le résultat.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b1d434-a464-40f8-ab6a-edd6415463c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image",
   "language": "python",
   "name": "image"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
